{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T20:45:00.220255Z",
     "start_time": "2020-04-28T20:45:00.205430Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClusterFile:\n",
    "    types = {\n",
    "        'typ' : (str, '%s'),\n",
    "        'il' : (int, '%d'),\n",
    "        'ip' : (int, '%d'),\n",
    "        'ra' : (float, '%.4f'),\n",
    "        'dec' : (float, '%.4f'),\n",
    "        'st' : (str, '%s'),\n",
    "        'amo' : (int, '%d'),\n",
    "        'in' : (int, '%d'),\n",
    "        'dia' : (float, '%.4f'),\n",
    "        'nside' : (int, '%d'),\n",
    "        'len' : (int, '%d')\n",
    "\n",
    "    }\n",
    "\n",
    "    def __init__(self, name):\n",
    "        import re\n",
    "        \n",
    "        #cut .npy.csv.mov.avi.rar\n",
    "        end = re.findall(r'\\.\\D+', name)\n",
    "        if len(end) > 0:\n",
    "            name = name[:-len(end[-1])]\n",
    "        \n",
    "        words = re.split('_', name)\n",
    "        self.params = {}\n",
    "        for p in self.types:\n",
    "            self.params[p] = None\n",
    "    \n",
    "        for param in self.params:\n",
    "            for word in words:\n",
    "                m = re.match(param, word)\n",
    "                if not m is None:\n",
    "                    self.params[param] = self.types[param][0](word[m.end():])\n",
    "    \n",
    "    def file(self, end=''):\n",
    "        res = ''\n",
    "        for p in self.params:\n",
    "            if not self.params[p] is None:\n",
    "                res += p\n",
    "                res += self.types[p][1] % self.params[p]\n",
    "                res += '_'\n",
    "        res = res[:-1]\n",
    "        return res + end\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.params[key]\n",
    "    def __setitem__(self, key, item):\n",
    "        self.params[key] = item\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:51.284Z"
    }
   },
   "outputs": [],
   "source": [
    "def pix2ra_dec(pix, nside=2**17):\n",
    "    import healpy as hp\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    from astropy import units as u\n",
    "    l, b = hp.pix2ang(nest=True, ipix=pix, nside=nside, lonlat=True)\n",
    "    sc = SkyCoord(l=l*u.degree, b=b*u.degree, frame='galactic')\n",
    "    return sc.icrs.ra.degree, sc.icrs.dec.degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:51.711Z"
    }
   },
   "outputs": [],
   "source": [
    "def pix2pix(pix, nside1=2**10, nside2=2**17):\n",
    "    import healpy as hp\n",
    "    vec = hp.pix2vec(nest=True, nside=nside1, ipix=pix)\n",
    "    return hp.vec2pix(x=vec[0], y=vec[1], z=vec[2], nside=nside2, nest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:52.083Z"
    }
   },
   "outputs": [],
   "source": [
    "def dist_ra_dec(coords1, coords2):\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    from astropy import units as u\n",
    "    sc1 = SkyCoord(ra=coords1[0] * u.degree, \n",
    "                   dec=coords1[1] * u.degree, frame='icrs')\n",
    "    sc2 = SkyCoord(ra=coords2[0] * u.degree, \n",
    "                   dec=coords2[1] * u.degree, frame='icrs')\n",
    "    return sc1.separation(sc2).degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:52.474Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_patches_coords(cat, n, id_list, maxradius, minradius, inpix, dirname, clstdir, nside = 2**17, \n",
    "                       try_search=False, nsidet=2**10):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from os.path import join\n",
    "    from os import walk\n",
    "    import healpy as hp\n",
    "    from astropy.coordinates import SkyCoord\n",
    "    from astropy import units as u\n",
    "    \n",
    "    def gen_all_pixels(cat, nsidet=2**10):\n",
    "        all_pixels = None\n",
    "        if try_search:\n",
    "            files = next(walk('/home/rt2122/data/new/all_pixels/'))[-1]\n",
    "            resfile = None\n",
    "            for f in files:\n",
    "                cf = ClusterFile(f)\n",
    "                if cf['in'] == inpix and minradius - cf['dia'] < 0.1:\n",
    "                    resfile = f\n",
    "                    break\n",
    "            if not resfile is None:\n",
    "                all_pixels = pd.read_csv(join('~/data/new/all_pixels', resfile), index_col='index')\n",
    "        if all_pixels is None:\n",
    "            cat = cat[cat['pix'] == inpix]\n",
    "            cat.index = np.arange(cat.shape[0])\n",
    "            all_pixels = np.array([])\n",
    "            for i in range(cat.shape[0]):\n",
    "                sc = SkyCoord(ra=cat['ra'][i]*u.degree,\n",
    "                             dec=cat['dec'][i]*u.degree, frame='icrs')\n",
    "                vec = hp.ang2vec(sc.galactic.l.degree, \n",
    "                                 sc.galactic.b.degree, lonlat=True)\n",
    "                pixels = hp.query_disc(nside=nsidet, nest=True, vec=vec, \n",
    "                                       radius=np.radians(minradius)).flatten()\n",
    "                all_pixels = np.concatenate([all_pixels, pixels])\n",
    "            all_pixels = all_pixels.astype(np.int64)\n",
    "            if try_search:\n",
    "                all_cf = ClusterFile('')\n",
    "                all_cf['typ'] = 'allp'\n",
    "                all_cf['in'] = inpix\n",
    "                all_cf['dia'] = minradius\n",
    "                \n",
    "                np.save(join('/home/rt2122/data/new/all_pixels/', all_cf.file()), all_pixels)\n",
    "        return all_pixels\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_pixels = gen_all_pixels(cat, nsidet)\n",
    "    idxs = []\n",
    "    for i in range(n):\n",
    "        idx = np.random.choice(all_pixels)\n",
    "        idxs.append(idx)\n",
    "        all_pixels = all_pixels[all_pixels != idx]\n",
    "    \n",
    "    cen = pd.DataFrame({'ra' : None,\n",
    "                       'dec' : None,\n",
    "                       'pix' : idxs})\n",
    "    \n",
    "    cf = ClusterFile('')\n",
    "    cf['typ'] = 'clust'\n",
    "    cf['il'] = id_list\n",
    "    cf['in'] = inpix\n",
    "    for i in range(n):\n",
    "        cen['pix'][i] = pix2pix(cen['pix'][i], nside1=nsidet, nside2=nside)\n",
    "        cen['ra'][i], cen['dec'][i] = pix2ra_dec(nside=nside, pix=cen['pix'][i])\n",
    "        \n",
    "        dists = dist_ra_dec((cen['ra'][i], cen['dec'][i]), (cat['ra'], cat['dec']))\n",
    "        cl_pix = cat[dists < maxradius]\n",
    "        cf['ra'] = cen['ra'][i]\n",
    "        cf['dec'] = cen['dec'][i]\n",
    "        cf['ip'] = i\n",
    "        \n",
    "        cl_pix.index = np.arange(cl_pix.shape[0])\n",
    "        cl_pix.to_csv(join(clstdir, cf.file('.csv')))\n",
    "        \n",
    "    \n",
    "    cen.index.name='index'\n",
    "    \n",
    "    cf_cen = ClusterFile('')\n",
    "    cf_cen['typ'] = 'cen'\n",
    "    cf_cen['il'] = id_list\n",
    "    cf_cen['amo'] = n\n",
    "    cf_cen['in'] = inpix\n",
    "    cf_cen['dia'] = maxradius\n",
    "    \n",
    "    cen.to_csv(join(dirname, cf_cen.file('.csv')))\n",
    "    \n",
    "    return cen\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:52.866Z"
    }
   },
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:53.198Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_patches_list(listname, downloaddir, st=0):\n",
    "    from only_colab import get_patch\n",
    "    import pandas as pd\n",
    "    from os.path import join, basename\n",
    "    from tqdm import tqdm_notebook\n",
    "    \n",
    "    cen = pd.read_csv(listname, index_col='index')\n",
    "    cf_cen = ClusterFile(basename(listname))\n",
    "    \n",
    "    cf = ClusterFile('')\n",
    "    cf['typ'] = 'dat'\n",
    "    cf['il'] = cf_cen['il']\n",
    "    cf['st'] = 'ne'\n",
    "    cf['in'] = cf_cen['in']\n",
    "    \n",
    "    for i in tqdm_notebook(range(st, cen.shape[0])):\n",
    "        cf['ip'] = i\n",
    "        cf['ra'] = cen['ra'][i]\n",
    "        cf['dec'] = cen['dec'][i]\n",
    "        file_name = join(downloaddir, cf.file('.csv'))\n",
    "        get_patch(cen['ra'][i], cen['dec'][i], cf_cen['dia'] * 60, \n",
    "                  job_name='p%d_%d' % (cf_cen['il'], i), file_name=file_name,\n",
    "                  table_name='p%d_%d' % (cf_cen['il'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:53.533Z"
    }
   },
   "outputs": [],
   "source": [
    "def galactic2pix(l, b, nside=2**17):\n",
    "    import healpy as hp\n",
    "    return hp.ang2pix(nside=nside, lonlat=True, nest=True, theta=l, phi=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:53.896Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_patches(files_list, cdir, files_dir):\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm_notebook\n",
    "    \n",
    "    \n",
    "    def remove_duplicates_patch(patch, drop_err=True):\n",
    "        import pandas as pd\n",
    "        duplicates = patch.loc[patch.duplicated(subset=[\"l\", \"b\"], keep='first')]\n",
    "        coords = set([(l, b) for l, b in zip(duplicates[\"l\"], duplicates[\"b\"])])\n",
    "        params = [f + par for f in 'grizy' for par in ['KronFlux', 'PSFFlux']]\n",
    "\n",
    "        for p in params:\n",
    "            idx = patch[patch[p+'Err'] < -200].index\n",
    "            patch[p+'Err'][idx] = np.nan\n",
    "            idx = patch[patch[p] < -200].index\n",
    "            patch[p][idx]=np.nan\n",
    "\n",
    "        for l, b in coords:\n",
    "            index = patch[np.logical_and(patch[\"l\"] == l, patch[\"b\"] == b)].index[0]\n",
    "            cur_duplicates = duplicates[duplicates[\"l\"] == l][duplicates[\"b\"] == b]\n",
    "            for p in params:\n",
    "                err = patch.loc[index, p+'Err']\n",
    "                min_err = min(cur_duplicates[p+'Err'])\n",
    "                if err > min_err:\n",
    "                    val = cur_duplicates[cur_duplicates[p+'Err']==min_err][p].values[0]\n",
    "                    patch.loc[index, p] = val\n",
    "\n",
    "        patch.drop_duplicates(subset=[\"l\", \"b\"], keep='first', inplace=True)\n",
    "        if drop_err:\n",
    "            params = [p + 'Err' for p in params]\n",
    "            patch.drop(params, axis='columns', inplace=True)\n",
    "\n",
    "        patch.index = np.arange(patch.shape[0])\n",
    "        return patch\n",
    "\n",
    "    def calc_pix(patch, nside=2**17):\n",
    "        import healpy as hp\n",
    "        \n",
    "        params = [f + par for f in 'grizy' for par in ['KronFlux', 'PSFFlux']]\n",
    "        patch['pix'] = np.zeros((patch.shape[0]), dtype=np.int64)\n",
    "        for i in tqdm_notebook(range(patch.shape[0])):\n",
    "            theta = patch.iloc[i][\"l\"]\n",
    "            phi = patch.iloc[i][\"b\"]\n",
    "            patch.loc[i,'pix'] = hp.ang2pix(theta=theta, phi=phi, \n",
    "                                             nside=nside, nest=True, lonlat=True)\n",
    "    \n",
    "        duplicates = patch.loc[patch.duplicated(subset=['pix'], keep=False)]\n",
    "        pixels = set(duplicates['pix'])\n",
    "        \n",
    "        patch.index = np.arange(patch.shape[0])\n",
    "        for pix in pixels:\n",
    "            index = patch[patch['pix'] == pix].index[0]\n",
    "            cur_duplicates = duplicates[duplicates['pix'] == pix]\n",
    "            for p in params:\n",
    "                max_ = max(cur_duplicates[p])\n",
    "        \n",
    "        patch.drop_duplicates(subset=['pix'], keep='first', inplace=True)\n",
    "            \n",
    "\n",
    "    from os.path import join\n",
    "    import pandas as pd\n",
    "    \n",
    "    for f in files_list:\n",
    "        cf = ClusterFile(f)\n",
    "        if cf['typ'] == 'dat' and cf['st'] == 'ne':\n",
    "            data = pd.read_csv(join(files_dir, f), index_col='index')\n",
    "            if 'Unnamed: 0' in list(data):\n",
    "                data.drop(['Unnamed: 0'], inplace=True)\n",
    "            first_len = data.shape[0]\n",
    "            remove_duplicates_patch(data)\n",
    "            calc_pix(data)\n",
    "            print(cf['ip'], ') Removed:', first_len - data.shape[0])\n",
    "            cf['st'] = 'cl'\n",
    "            f_clear = cf.file('.csv')\n",
    "            print(f_clear)\n",
    "            data.to_csv(join(cdir,f_clear))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:54.225Z"
    }
   },
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:54.628Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pic(center_pix, nside=2**17, size=2048):\n",
    "    import healpy as hp\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm_notebook\n",
    "\n",
    "    def get_neighbours(npix, direction=None):\n",
    "        theta, phi = hp.pix2ang(nside=nside, ipix=npix, nest=True)\n",
    "        neighbours = hp.get_all_neighbours(nside=nside, theta=theta, phi=phi, nest=True)\n",
    "        if direction is None:\n",
    "            return neighbours\n",
    "        dirs = ['sw', 'w', 'nw', 'n', 'ne', 'e', 'se', 's']\n",
    "        return neighbours[dirs.index(direction)]\n",
    "\n",
    "    ''' ~~~~~~~~~~> y \n",
    "      |  n __nw__ w\n",
    "      |    |    |\n",
    "    x | ne |    | sw\n",
    "      |    |    |\n",
    "      \\/ e ~~se~~ s\n",
    "\n",
    "    '''\n",
    "    half = size // 2\n",
    "    ans = np.ones((size, size), dtype=np.int64)\n",
    "    ans *= -1\n",
    "    ans[half - 1, half - 1] = center_pix\n",
    "    for i in range(half - 2, -1, -1):\n",
    "        ans[i, i] = get_neighbours(ans[i + 1, i + 1], 'n')\n",
    "    for i in range(1, size):\n",
    "        ans[i, 0] = get_neighbours(ans[i - 1, 0], 'se')\n",
    "    for i in tqdm_notebook(range(size)):\n",
    "        for j in range(1, size):\n",
    "            if ans[i, j] == -1:\n",
    "                ans[i, j] = get_neighbours(ans[i, j - 1], 'sw')\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:54.965Z"
    }
   },
   "outputs": [],
   "source": [
    "def pix2dict(matr):\n",
    "    ans = {}\n",
    "    for i in range(matr.shape[0]):\n",
    "        for j in range(matr.shape[1]):\n",
    "            ans[matr[i, j]] = (i, j)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:55.289Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_matrix_files(cenfile, cendir, mtxdir):\n",
    "    from os.path import join\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    cen = pd.read_csv(join(cendir, cenfile), index_col='index')\n",
    "    cf_cen = ClusterFile(cenfile)\n",
    "    cf = ClusterFile('')\n",
    "    cf['typ']='mtx'\n",
    "    cf['len'] = 2048\n",
    "    \n",
    "    for i in range(cen.shape[0]):\n",
    "        cf['ip'] = i\n",
    "        cf['ra'] = cen['ra'][i]\n",
    "        cf['dec'] = cen['dec'][i]\n",
    "        \n",
    "        mtx = make_pic(cen['pix'][i])\n",
    "        \n",
    "        np.save(join(mtxdir, cf.file()), mtx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:55.644Z"
    }
   },
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:55.992Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualisation(filename, mtxname, size=2048, p = 80, invert=True):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from skimage.draw import circle\n",
    "    from os.path import join\n",
    "    from tqdm import tqdm_notebook\n",
    "    \n",
    "    patch = pd.read_csv(filename)\n",
    "    mtx = pix2dict(np.load(mtxname))\n",
    "    ans = np.zeros((size, size), dtype=np.uint8)\n",
    "    print(patch['iKronFlux'].min(), patch['iKronFlux'].max())\n",
    "    for i in tqdm_notebook(range(patch.shape[0])):\n",
    "        pix = patch['pix'][i]\n",
    "        if pix in mtx:\n",
    "            x, y = mtx[pix]\n",
    "            flux = patch['iKronFlux'][i]\n",
    "            if np.isnan(flux) or flux==-999:\n",
    "                continue\n",
    "            flux *= p\n",
    "            ans[circle(x, y, radius=flux, shape=ans.shape)] = 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:56.419Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_mask(clstname, mtxname, clust_rad=0.04, size=2048):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from os.path import join\n",
    "    from tqdm import tqdm_notebook\n",
    "    import healpy as hp\n",
    "    \n",
    "    \n",
    "    def ra_dec2vec(ra, dec):\n",
    "        from astropy.coordinates import SkyCoord\n",
    "        import astropy.units as u\n",
    "        \n",
    "        sc = SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "        return hp.ang2vec(lonlat=True, theta=sc.galactic.l.degree, phi=sc.galactic.b.degree)\n",
    "    \n",
    "    clst = pd.read_csv(clstname)\n",
    "    mtx = pix2dict(np.load(mtxname))\n",
    "    \n",
    "    pixels = []\n",
    "    for i in range(clst.shape[0]):\n",
    "        vec = ra_dec2vec(clst['ra'][i], clst['dec'][i])\n",
    "        pixels.extend(hp.query_disc(nside=2**17, vec=vec, nest=True, radius=np.radians(clust_rad)))\n",
    "        \n",
    "    ans = np.zeros((size, size), dtype=np.uint8)\n",
    "    \n",
    "    for pix in pixels:\n",
    "        if pix in mtx:\n",
    "            ans[mtx[pix]] = 1\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:56.782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999.0 0.212365001440048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc245ae094de4c128a6df158d88d48ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=108417), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vis = visualisation('/home/rt2122/data/new/try/cl/typdat_il0_ip0_ra90.2878_dec86.1793_stcl_in4.csv', \n",
    "                   '/home/rt2122/data/new/try/mtx/typmtx_ip0_ra90.2878_dec86.1793_len2048.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:57.126Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = make_mask('/home/rt2122/data/new/try/clst/typclust_il0_ip0_ra90.2878_dec86.1793_in4.csv', \n",
    "                '/home/rt2122/data/new/try/mtx/typmtx_ip0_ra90.2878_dec86.1793_len2048.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:57.633Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:58.030Z"
    }
   },
   "outputs": [],
   "source": [
    "vis *= 255\n",
    "mask *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T20:44:58.597Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(np.dstack([vis, vis, mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
